\def\baselinestretch{1}
\chapter{Analysis and Conclusions}
\ifpdf
    \graphicspath{{Conclusions/ConclusionsFigs/PNG/}{Conclusions/ConclusionsFigs/PDF/}{Conclusions/ConclusionsFigs/}}
\else
    \graphicspath{{Conclusions/ConclusionsFigs/EPS/}{Conclusions/ConclusionsFigs/}}
\fi

\def\baselinestretch{1.66}

In this project we have implemented a sign classifier able to distinguish between signs performed in front of the Kinect sensor. To do this we implemented classes which extend Hidden Markov Models to accept continuous input streams and translate them via k-means clustering to a sequence in a discrete observation space. We then combined left-right topology HMMs in a novel way to form \verb|signModel| objects which use information about all of the joints the Kinect sensor tracks to determine the likelihood that a given sign was performed. Finally we trained these models on a training set and used a hold-out data set to determine optimal parameter values for the acceptance threshold value and number of clusters in the quantization algorithm.

When tested on a test set of 10 instances of each of the 20 signs we found the classifier had an accuracy of 81.6\% without a grammer restriction and 92.3\% when a grammar restriction. These values are not drastically lower than the recognition accuracy when tested on the hold-out set or training set and suggest that the classifier has not suffered too much from overfitting. These recognition rates are quite impressive as our classifier differentiates between actual signs of British Sign Language without ever considering the hands and are better than we had expected to achieve when we began the project.

Whilst certainly of some use the classifier implemented in this project is not anywhere near a full translation system for BSL as it does not account for the fingers, hand shape of non-manual features of the language. As we have seen this greatly restricts the expressiveness of our system as we require information about the fingers to distinguish certain signs or information about the face to pose questions. Further we have seen that as the number of signs in the dictionary increases the misclassification rate also increases and it follows that the methods used to build our classifier will perform considerably worse when expected to recognise signs from a full lexicon of thousands of words in BSL even if a strict grammar is enforced.

Our classifier's overall accuracy was lower than that of \citet{yamato1992recognizing} which had an average accuracy of 96.0\% for six full body gestures. As our classifier was expected distinguish between more gestures it is no surprise that it has overall accuracy lower than this. However when restricted to a set of only six signs our classifier can have an accuracy between 94\% and 100\%, depending on the choice of signs, which suggests our model is at least as effective as that of Yamato.

\citet{starner1995real} used continuous distribution Hidden Markov Models to build a sign classifier which achieved an accuracy of 90.7\% without a grammar restriction and 97.0\% with a grammar restriction on a test set of 496 sentences drawn from a vocabulary of 40 words of American Sign Language. However their classifier also made use of the shape of the hands during the sign and if such information were available to the our classifier the accuracy would certainly be improved. Nevertheless their results suggest that the method of continuous distribution Hidden Markov Models is worth considering.

%%% ----------------------------------------------------------------------

% ------------------------------------------------------------------------

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
