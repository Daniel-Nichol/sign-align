\chapter{Additional Work}
\ifpdf
    \graphicspath{{Chapter3/Chapter3Figs/PNG/}{Chapter3/Chapter3Figs/PDF/}{Chapter3/Chapter3Figs/}}
\else
    \graphicspath{{Chapter3/Chapter3Figs/EPS/}{Chapter3/Chapter3Figs/}}
\fi

\section{Improvements to the Current Classifier}
An immediate improvement that could be made to the sign recognition system is to gather training data from a user fluent in British Sign Language. This would likely improve the recognition accuracy of our system as the training sets would be more consistent. As we have implemented an efficient way to gather training sets through the Kinect Sensor this could be achieved fairly easily for a small training set, however it would still be prohibitively time consuming for a single user to generate the training sets for a large dictionary of signs. As the Kinect Sensor is widely available this problem might be solved by crowd-sourcing the training database and allowing users of the system to submit their own training data for new signs.

In building our system we decided to use Hidden Markov Models with discrete observation space over those with continuous observation space. It could be argued that continuous density HMMs might be more suitable for the task of gesture recognition as each individual rendition of a sign can be considered as being normally distributed about some ``true'' path which defines the actual sign. As such we may be able to model the sign much more effictively by using a continuous density Hidden Markov Model in which the probability distribution is some mixture of Gaussians. Failing this we might attempt to implement a more effective discretisation of continous space. At present we are using Lloyd's algorithm to cluster the input space and this can create small or empty clusters if the cluster number is too high. We could see significant improvements if we implemented a clustering algorithm which ensures no empty clusters and attempts to make clusters evenly sized where possible.

\section{Extensions of SignAlign}
An extension of the system to track hands and factor their positions into predicting signs would likely yield significant improvments to sign recognition. For example the signs for ``you'' and ``you'' which are essentially the same if the hand is ignored and are differentiated by a pointing finger or the hand forming a fist cannot be accurately differentiated by the current system. At present the Kinect SDK does not provide information about the locations of the fingers or shapes of the hands and so the system cannot be extended to use hand shapes without using third party software or implementing our own finger tracking; however it is expected that the Kinect will soon be updated to provide hand tracking and so we may be able to use hand tracking in the near future using only the Kinect SDK.

If hand tracking is implemented then we will be able to significantly extend the functionality of our sign recognition system to detect finger spelling. Finger spelling is commonly used in sign language to communicate words with no sign equivalent and is a key part of communicating in sign language. As such the ability to accurately finger spell is integral to a full sign language translation system could be used to overcome the problem of not having training data for a large dictionary - by allowing a user to finger spell those words not yet available. The finger spelling problem consists of detecting between 26 distinct letter signs and could be solved using a similar Hidden Markov Model technique to the one presented in this project; by replacing joint tracking with finger and knuckle tracking. As we have obtained a good accuracy in classifying a small dictionary of signs it suggests that this method might produce good results in classifying the different letter signs of finger spelling.

Another feature of sign language which we have ignore in this project is facial expressions. Facial expressions are often used to modify the signs being communicated by the hands. For example the sign ``you'' can be converted to ``are you ...?'' by raising the eyebrows. The Kinect SDK has been used to track facial expressions~\citep{Microsoft:2013:Face} and this work could be intergrated with the sign recognition to produce a more robust sign recognition system.

% ------------------------------------------------------------------------


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
